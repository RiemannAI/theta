{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Process PoolWorker-1:\n",
      "Process PoolWorker-6:\n",
      "Process PoolWorker-8:\n",
      "Traceback (most recent call last):\n",
      "Process PoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "Process PoolWorker-7:\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Process PoolWorker-2:\n",
      "Process PoolWorker-4:\n",
      "Traceback (most recent call last):\n",
      "Process PoolWorker-5:\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/usr/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/usr/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    task = get()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/usr/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/usr/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/usr/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    task = get()\n",
      "    task = get()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    task = get()\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 374, in get\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 374, in get\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 374, in get\n",
      "  File \"/usr/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 374, in get\n",
      "    racquire()\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "    return recv()\n",
      "    racquire()\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 374, in get\n",
      "    task = get()\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 374, in get\n",
      "  File \"/usr/lib/python2.7/multiprocessing/pool.py\", line 102, in worker\n",
      "KeyboardInterrupt\n",
      "    task = get()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 374, in get\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "    racquire()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "from rtbm.riemann_theta.riemann_theta import RiemannTheta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import theano\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, Reshape  \n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import time\n",
    "\n",
    "from rtbm import RTBM, minimizer\n",
    "\n",
    "import rtbm.layers as layers\n",
    "import rtbm.model as mdl\n",
    "\n",
    "from rtbm.costfunctions import mse\n",
    "from rtbm.activations import sigmoid, linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "MNIST_train = pd.read_csv('~/data/mnist_train.csv', delimiter=\",\",header=None).values\n",
    "MNIST_test  = pd.read_csv('~/data/mnist_test.csv', delimiter=\",\",header=None).values\n",
    "\n",
    "# Prepare data (normalized onto [0,1])\n",
    "Y_train = MNIST_train[0:10000,0]\n",
    "X_train = MNIST_train[0:10000,1:]/255.0\n",
    "\n",
    "Y_test = MNIST_test[:,0]\n",
    "X_test = MNIST_test[:,1:]/255.0\n",
    "\n",
    "enc = LabelBinarizer()\n",
    "enc.fit(np.diag([1,1,1,1,1,1,1,1,1,1]))\n",
    "enc.classes_ = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "T=enc.transform(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras (500 linear + 100 linear + 1 linear + MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() \n",
    "\n",
    "model.add(Dense(500,  input_dim=784))\n",
    "model.add(Activation('linear'))\n",
    "#model.add(Dense(100,  input_dim=784))\n",
    "#model.add(Activation('linear'))\n",
    "model.add(Dense(output_dim=1))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "\n",
    "sgd = SGD(lr=0.001)\n",
    "\n",
    "tic = time.clock()\n",
    "\n",
    "model.compile(loss='mse', optimizer=sgd)\n",
    "\n",
    "toc = time.clock()\n",
    "\n",
    "print(\"Compile time: \",toc-tic)\n",
    "\n",
    "tic = time.clock()\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=10000, nb_epoch=100, validation_data=None, shuffle=False, verbose=1)  \n",
    "toc = time.clock()\n",
    "\n",
    "print(\"Run time: \",toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On train set\n",
    "P=np.abs(np.round(np.real(model.predict(X_train)))).flatten()\n",
    "\n",
    "\n",
    "print(classification_report(Y_train,P.T))\n",
    "print(confusion_matrix(Y_train, P.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On test set\n",
    "P=np.abs(np.round(np.real(model.predict(X_test)))).flatten()\n",
    "\n",
    "\n",
    "print(classification_report(Y_test,P.T))\n",
    "print(confusion_matrix(Y_test, P.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Theta and SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = mdl.Model()\n",
    "M.add(layers.NonLinear(784,500,linear()))\n",
    "#M.add(layers.NonLinear(500,100,linear()))\n",
    "M.add(layers.NonLinear(500,1,linear()))\n",
    "\n",
    "minim = minimizer.SGD()\n",
    "sol=minim.train(mse(), M, np.transpose(X_train), Y_train.reshape(1,len(Y_train)), lr=0.001, maxiter=100, batch_size=10000, log_step=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On train set\n",
    "P=np.abs(np.round(np.real(M.predict(np.transpose(X_train)))))\n",
    "\n",
    "print(classification_report(Y_train,P.T))\n",
    "print(confusion_matrix(Y_train, P.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On train set\n",
    "P=np.abs(np.round(np.real(M.predict(np.transpose(X_train)))))\n",
    "\n",
    "print(classification_report(Y_train,P.T))\n",
    "print(confusion_matrix(Y_train, P.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras (200 sigmoids + 10 sigmoids + 1 linear + MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() \n",
    "\n",
    "model.add(Dense(10,  input_dim=784))\n",
    "model.add(Activation('sigmoid'))\n",
    "#model.add(Dense(10))\n",
    "#model.add(Activation('sigmoid'))\n",
    "model.add(Dense(output_dim=1))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "\n",
    "sgd = SGD(lr=0.1)\n",
    "\n",
    "tic = time.clock()\n",
    "\n",
    "model.compile(loss='mse', optimizer=sgd)\n",
    "\n",
    "toc = time.clock()\n",
    "\n",
    "print(\"Compile time: \",toc-tic)\n",
    "\n",
    "tic = time.clock()\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=10000, nb_epoch=200, validation_data=None, shuffle=False, verbose=0)  \n",
    "toc = time.clock()\n",
    "\n",
    "print(\"Run time: \",toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On train set\n",
    "P=np.abs(np.round(np.real(model.predict(X_train)))).flatten()\n",
    "\n",
    "\n",
    "print(classification_report(Y_train,P.T))\n",
    "print(confusion_matrix(Y_train, P.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On test set\n",
    "P=np.abs(np.round(np.real(model.predict(X_test)))).flatten()\n",
    "\n",
    "\n",
    "print(classification_report(Y_test,P.T))\n",
    "print(confusion_matrix(Y_test, P.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Theta and SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = mdl.Model()\n",
    "M.add(layers.NonLinear(784,10,sigmoid()))\n",
    "#M.add(layers.NonLinear(200,10,sigmoid()))\n",
    "M.add(layers.Linear(10,1))\n",
    "\n",
    "minim = minimizer.SGD()\n",
    "sol=minim.train(mse(), M, np.transpose(X_train), Y_train.reshape(1,len(Y_train)), lr=0.1, maxiter=200, batch_size=10000, log_step=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On train set\n",
    "P=np.abs(np.round(np.real(M.predict(np.transpose(X_train)))))\n",
    "\n",
    "print(classification_report(Y_train,P.T))\n",
    "print(confusion_matrix(Y_train, P.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On test set\n",
    "P=np.abs(np.round(np.real(M.predict(np.transpose(X_test)))))\n",
    "\n",
    "print(classification_report(Y_test,P.T))\n",
    "print(confusion_matrix(Y_test, P.T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras (200 sigmoids + 10 Softmax + MSE)Â¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Compile time: ', 0.08836900000005699)\n",
      "('Run time: ', 60.80085400000007)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() \n",
    "\n",
    "model.add(Dense(200,  input_dim=784))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10,  input_dim=784))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "sgd = SGD(lr=0.001)\n",
    "\n",
    "tic = time.clock()\n",
    "\n",
    "model.compile(loss='mse', optimizer=sgd)\n",
    "\n",
    "toc = time.clock()\n",
    "\n",
    "print(\"Compile time: \",toc-tic)\n",
    "\n",
    "tic = time.clock()\n",
    "\n",
    "model.fit(X_train, T, batch_size=1000, nb_epoch=100, validation_data=None, shuffle=False, verbose=0)  \n",
    "toc = time.clock()\n",
    "\n",
    "print(\"Run time: \",toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00      1001\n",
      "          1       0.00      0.00      0.00      1127\n",
      "          2       0.00      0.00      0.00       991\n",
      "          3       0.00      0.00      0.00      1032\n",
      "          4       0.23      0.18      0.20       980\n",
      "          5       0.00      0.00      0.00       863\n",
      "          6       0.00      0.00      0.00      1014\n",
      "          7       0.14      0.01      0.02      1070\n",
      "          8       0.09      0.92      0.17       944\n",
      "          9       0.00      0.00      0.00       978\n",
      "\n",
      "avg / total       0.05      0.10      0.04     10000\n",
      "\n",
      "[[   0    0    0    0  225    0    0   11  765    0]\n",
      " [   0    0    0    0    0    0    0    0 1127    0]\n",
      " [   0    0    0    0   33    0    0    6  952    0]\n",
      " [   0    0    0    0   25    0    0    8  999    0]\n",
      " [   0    0    0    0  172    0    0    4  804    0]\n",
      " [   0    0    0    0   73    0    0    1  789    0]\n",
      " [   0    0    0    0   89    0    0    4  921    0]\n",
      " [   0    0    0    0   65    0    0    9  996    0]\n",
      " [   0    0    0    0   62    0    0   14  868    0]\n",
      " [   0    0    0    0   20    0    0    7  951    0]]\n"
     ]
    }
   ],
   "source": [
    "# On train set\n",
    "P=np.argmax(model.predict(X_train),axis=1)\n",
    "\n",
    "print(classification_report(Y_train,P.T))\n",
    "print(confusion_matrix(Y_train, P.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       980\n",
      "          1       0.00      0.00      0.00      1135\n",
      "          2       0.00      0.00      0.00      1032\n",
      "          3       0.00      0.00      0.00      1010\n",
      "          4       0.18      0.15      0.16       982\n",
      "          5       0.00      0.00      0.00       892\n",
      "          6       0.00      0.00      0.00       958\n",
      "          7       0.07      0.01      0.01      1028\n",
      "          8       0.09      0.88      0.17       974\n",
      "          9       0.00      0.00      0.00      1009\n",
      "\n",
      "avg / total       0.03      0.10      0.03     10000\n",
      "\n",
      "[[   0    0    0    0  262    0    0    5  713    0]\n",
      " [   0    0    0    0    0    0    0    0 1135    0]\n",
      " [   0    0    0    0   37    0    0   11  984    0]\n",
      " [   0    0    0    0   29    0    0    9  972    0]\n",
      " [   0    0    0    0  148    0    0    2  832    0]\n",
      " [   0    0    0    0   72    0    0    9  811    0]\n",
      " [   0    0    0    0  106    0    0    4  848    0]\n",
      " [   0    0    0    0   45    0    0    6  977    0]\n",
      " [   0    0    0    0   89    0    0   30  855    0]\n",
      " [   0    0    0    0   27    0    0    9  973    0]]\n"
     ]
    }
   ],
   "source": [
    "# On test set\n",
    "P=np.argmax(model.predict(X_test),axis=1)\n",
    "\n",
    "print(classification_report(Y_test,P.T))\n",
    "print(confusion_matrix(Y_test, P.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Batch C: ', 0.9096904861920732)\n",
      "Iteration 0 in 0.75(s), cost = 0.908560\n",
      "('Batch C: ', 0.9035433808556956)\n",
      "Iteration 10 in 6.03(s), cost = 0.902852\n",
      "('Batch C: ', 0.9022354225371491)\n",
      "Iteration 20 in 11.33(s), cost = 0.901163\n",
      "('Batch C: ', 0.9029663782921442)\n",
      "Iteration 30 in 16.73(s), cost = 0.901145\n",
      "('Batch C: ', 0.9023120790327643)\n",
      "Iteration 40 in 21.99(s), cost = 0.900584\n",
      "('Batch C: ', 0.9012368225864998)\n",
      "Iteration 50 in 27.26(s), cost = 0.900238\n",
      "('Batch C: ', 0.9000391550477479)\n",
      "Iteration 60 in 32.46(s), cost = 0.899322\n",
      "('Batch C: ', 0.9004836578809717)\n",
      "Iteration 70 in 37.61(s), cost = 0.899173\n",
      "('Batch C: ', 0.9004952675355563)\n",
      "Iteration 80 in 42.83(s), cost = 0.898937\n",
      "('Batch C: ', 0.8994279630427919)\n",
      "Iteration 90 in 48.04(s), cost = 0.898765\n",
      "('Batch C: ', 0.898792103776735)\n",
      "Iteration 100 in 53.30(s), cost = 0.898219\n",
      "('Batch C: ', 0.899715911597967)\n",
      "Iteration 110 in 58.57(s), cost = 0.898208\n",
      "('Batch C: ', 0.8989355617914094)\n",
      "Iteration 120 in 63.82(s), cost = 0.898200\n",
      "('Batch C: ', 0.8981340384594594)\n",
      "Iteration 130 in 69.09(s), cost = 0.897796\n",
      "('Batch C: ', 0.899274770503883)\n",
      "Iteration 140 in 74.38(s), cost = 0.897878\n",
      "('Batch C: ', 0.8984116844831167)\n",
      "Iteration 150 in 79.07(s), cost = 0.897882\n",
      "('Batch C: ', 0.8980617701150185)\n",
      "Iteration 160 in 84.28(s), cost = 0.897669\n",
      "('Batch C: ', 0.89894672103581)\n",
      "Iteration 170 in 89.11(s), cost = 0.897708\n",
      "('Batch C: ', 0.8980054389157195)\n",
      "Iteration 180 in 93.83(s), cost = 0.897755\n",
      "('Batch C: ', 0.8985700025143611)\n",
      "Iteration 190 in 98.97(s), cost = 0.897883\n",
      "('Cost: ', 0.898676470882855)\n",
      "('Sol: ', array([ 0.05695181,  0.07147984,  0.07432752, ..., -0.26485641,\n",
      "       -0.40805596, -0.36205627]))\n",
      "Time: 103 s\n"
     ]
    }
   ],
   "source": [
    "M = mdl.Model()\n",
    "M.add(layers.NonLinear(784,200,sigmoid()))\n",
    "M.add(layers.Linear(200,10))\n",
    "M.add(layers.SoftMaxLayer(10))\n",
    "\n",
    "minim = minimizer.SGD()\n",
    "sol=minim.train(mse(), M, np.transpose(X_train), T.T, lr=0.001, maxiter=200, batch_size=1000, log_step=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.06      0.11      1001\n",
      "          1       0.50      0.00      0.00      1127\n",
      "          2       0.08      0.06      0.07       991\n",
      "          3       0.14      0.00      0.01      1032\n",
      "          4       0.09      0.44      0.15       980\n",
      "          5       0.00      0.00      0.00       863\n",
      "          6       0.05      0.04      0.05      1014\n",
      "          7       0.04      0.02      0.02      1070\n",
      "          8       0.00      0.00      0.00       944\n",
      "          9       0.20      0.63      0.31       978\n",
      "\n",
      "avg / total       0.17      0.12      0.07     10000\n",
      "\n",
      "[[ 64   0   1   4 386   0  78 369   2  97]\n",
      " [  0   1 526   0 443   0 113   0   0  44]\n",
      " [  3   0  62   0 674   0  65   8   1 178]\n",
      " [ 30   0 122   3 518   2  92  15   1 249]\n",
      " [  3   1  17   1 434   0  70  15   0 439]\n",
      " [ 20   0  11   4 423   0  90  32   2 281]\n",
      " [  0   0  13   1 756   0  42   3   0 199]\n",
      " [  1   0  10   7 442   0  91  18   2 499]\n",
      " [  0   0  45   0 354   1 104  10   0 430]\n",
      " [  0   0   9   1 300   0  49   1   0 618]]\n"
     ]
    }
   ],
   "source": [
    "P=np.argmax(M.predict(np.transpose(X_train)),axis=0)\n",
    "\n",
    "print(classification_report(Y_train,P.T))\n",
    "print(confusion_matrix(Y_train, P.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.08      0.13       980\n",
      "          1       0.00      0.00      0.00      1135\n",
      "          2       0.09      0.06      0.07      1032\n",
      "          3       0.18      0.00      0.01      1010\n",
      "          4       0.10      0.48      0.17       982\n",
      "          5       0.00      0.00      0.00       892\n",
      "          6       0.06      0.05      0.05       958\n",
      "          7       0.04      0.01      0.02      1028\n",
      "          8       0.00      0.00      0.00       974\n",
      "          9       0.19      0.65      0.29      1009\n",
      "\n",
      "avg / total       0.13      0.13      0.07     10000\n",
      "\n",
      "[[ 74   0   3   4 381   1  80 323   4 110]\n",
      " [  0   0 472   0 545   0  92   0   0  26]\n",
      " [  3   0  64   0 642   0  70  10   1 242]\n",
      " [ 14   0  79   4 517   0  95  12   7 282]\n",
      " [  1   0  17   1 467   0  47  11   0 438]\n",
      " [ 16   0  10   6 335   0 118  21   1 385]\n",
      " [  8   0  14   0 606   0  45   3   0 282]\n",
      " [  2   0  10   4 427   0  94  15   0 476]\n",
      " [  2   0  32   3 266   1 101  11   0 558]\n",
      " [  1   0   9   0 301   0  39   6   0 653]]\n"
     ]
    }
   ],
   "source": [
    "P=np.argmax(M.predict(np.transpose(X_test)),axis=0)\n",
    "\n",
    "\n",
    "print(classification_report(Y_test,P.T))\n",
    "print(confusion_matrix(Y_test, P.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
